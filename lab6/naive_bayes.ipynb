{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a84437",
   "metadata": {},
   "source": [
    "# Naive Bayes with sklearn\n",
    "\n",
    "We saw in class that Naive Bayes is a probabilistic classifier, that can easily support categorical and quantitative variables.\n",
    "\n",
    "Problem is ... `sklearn` does not natively work with both ...\n",
    "\n",
    "We will need to split again our data in quantitative and qualitative, and then code our own suggestions to take both into account.\n",
    "\n",
    "You can start with quantitative or qualitative data depending on the majority data type in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42573148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"../titanic.csv\").fillna(method=\"backfill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8536aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My target is survived \n",
    "y = df.Survived.values\n",
    "# For demonstration, I'm taking only 4 columns\n",
    "categorical_variables = [\"Sex\", \"Embarked\"]\n",
    "quantitative_variables = [\"Age\", \"Fare\"]\n",
    "X = df[categorical_variables + quantitative_variables].values\n",
    "X_quantitative = df[quantitative_variables].values\n",
    "X_categorical = df[categorical_variables].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb5b60",
   "metadata": {},
   "source": [
    "## Working with quantitative data\n",
    "With quantitative data, we can use the `GaussianNB` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15c0b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "680fcc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Training\n",
      "======= Prediction\n",
      "======= Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.95      0.78       549\n",
      "           1       0.72      0.22      0.33       342\n",
      "\n",
      "    accuracy                           0.67       891\n",
      "   macro avg       0.69      0.58      0.56       891\n",
      "weighted avg       0.68      0.67      0.61       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb = GaussianNB()\n",
    "\n",
    "print(\"======= Training\")\n",
    "gaussian_nb.fit(X_quantitative, y)\n",
    "\n",
    "print(\"======= Prediction\")\n",
    "predictions = gaussian_nb.predict(X_quantitative)\n",
    "\n",
    "print(\"======= Results\")\n",
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f180b1",
   "metadata": {},
   "source": [
    "**Questions**:\n",
    "1. Plot the statistical distribution of your variables and see if any is highly skewed.\n",
    "2. Apply Gaussian Naive Bayes to the quantitative variables of your dataset.\n",
    "3. Retrieve class probability and plot the results as a function of the different features, using heatmap colors.\n",
    "4. Perform k-fold cross-validation and return the classification scores (accuracy, recall, precision).\n",
    "6. Try removing highly correlated data and see if your results improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538b5f16",
   "metadata": {},
   "source": [
    "## Working with qualitative data\n",
    "With qualitative data, we can use the class CategoricalNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4958bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d252bb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Training\n",
      "======= Prediction\n",
      "======= Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.82       549\n",
      "           1       0.79      0.50      0.62       342\n",
      "\n",
      "    accuracy                           0.76       891\n",
      "   macro avg       0.77      0.71      0.72       891\n",
      "weighted avg       0.76      0.76      0.74       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb_categorical = CategoricalNB()\n",
    "\n",
    "print(\"======= Training\")\n",
    "gaussian_nb_categorical.fit(X_quantitative, y)\n",
    "\n",
    "print(\"======= Prediction\")\n",
    "predictions = gaussian_nb_categorical.predict(X_quantitative)\n",
    "\n",
    "print(\"======= Results\")\n",
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7682308c",
   "metadata": {},
   "source": [
    "**Questions**:\n",
    "1. Apply Gaussian Naive Bayes to the qualitative variables of your dataset.\n",
    "3. Retrieve class probability and plot the results as a function of the different features, using heatmap colors.\n",
    "4. Perform k-fold cross-validation and return the classification scores (accuracy, recall, precision).\n",
    "5. Compare to previous results.\n",
    "6. Transform every variable within your dataset to a qualitative using the class `sklearn.preprocessing.KBinsDiscretizer` and compare with previous results.\n",
    "7. Compare to what you achieved using `knn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6447f2",
   "metadata": {},
   "source": [
    "## Working with both data types\n",
    "It is annoying that sklearn does not allow to deal with both variables types...\n",
    "\n",
    "A solution to solve this is to:\n",
    "- Fit a GaussianNB on the quantitative variables and get the probabilities `quantitative_probabilities`\n",
    "- Fit a CategoricalNB on the qualitative variables `qualitative_probabilities`\n",
    "- Fit a new GaussianNB on the probbailities `quantitative_probabilities` and `qualitative_probabilities`.\n",
    "\n",
    "**Question**:\n",
    "1. Implement this solution and compare the results with what you obtained previously.\n",
    "2. **Bonus**: Suggest your own implementation using `sklearn` API for classifiers (see https://scikit-learn.org/stable/developers/develop.html).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
