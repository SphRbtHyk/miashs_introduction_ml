{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949f0928",
   "metadata": {},
   "source": [
    "# Lab3: Introduction to supervised learning\n",
    "This lab will be separated into two parts:\n",
    "\n",
    "1. First, we will code ourselves a random-based classifier and evaluate it using k-fold validation on the Pokemon dataset.\n",
    "\n",
    "2. We will learn to do the same thing using the [sklearn](https://scikit-learn.org/stable/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2656a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef23e7c8",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "Load the Pokemon dataset (or the `pre_processed.csv` one we did in the previous session)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d8ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../pokemon.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94b0b44",
   "metadata": {},
   "source": [
    "Extract 3 features of your choice into an array `X` and a target array `y` (conventional notations of `sklearn`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ecb2e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d3dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am only extracting a few subset of variables, \n",
    "# because we are working on the random classifier, but you can take all the features we studied last lab\n",
    "X = df[['sp_attack', 'sp_defense']].values\n",
    "y = df[\"is_legendary\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c664950",
   "metadata": {},
   "source": [
    "## Coding our own solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586918b5",
   "metadata": {},
   "source": [
    "### Coding a random classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715a1c80",
   "metadata": {},
   "source": [
    "1. Implement the simplest possible classifier: given a numpy vector and its ground truth, return a random value between 0 and 1 (use `numpy.random.binomial`). Make $p$ (the probability of being classified as 1) a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42fb8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_classifier(X, p: float = .5):\n",
    "    \"\"\"Random classifier: given a numpy vector X, return either the value 0 or 1, with probability p.\n",
    "    \n",
    "    Example:\n",
    "        random_classifier(np.array([1, 2, 3])) returns 1\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca01dee",
   "metadata": {},
   "source": [
    "2. Apply this classifier on all values in the `X` numpy matrix and store it in `y_predict`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc8366",
   "metadata": {},
   "source": [
    "3. Create the four evaluation functions we saw during lecture 4, that takes as iput :\n",
    "- `accuracy`\n",
    "- `recall`\n",
    "- `f1_score`\n",
    "- `precision`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f10c6a",
   "metadata": {},
   "source": [
    "4. Apply these functions to `y` and `y_predict` and draw conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b85f9e",
   "metadata": {},
   "source": [
    "We can see that all scores are above .5, value that should be used to compare the quality of our algorithms to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e8d4e",
   "metadata": {},
   "source": [
    "### Separation between tests and train\n",
    "We will evaluate our algorithm by \"training\" it on a subset of the data `X_train`, `y_train` and evaluate it on the data `X_test`, and compare `y_test` with the ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61544d31",
   "metadata": {},
   "source": [
    "1. Is there a training phase of the random classifier ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb314bd7",
   "metadata": {},
   "source": [
    "2. Create a function `split_train_test` that takes as input a matrix `X` and a target `y` and randomly splits into two matrixes `X_train` and `X_test` and a target `y_train` and `y_test`. You can use the function `numpy.random.choice`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41404f7d",
   "metadata": {},
   "source": [
    "3. Predict the value on the test dataset `X_test` on `y_test_predict`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4421e887",
   "metadata": {},
   "source": [
    "4. Compute the accuracy, precision, recall, f1_score by comparing `y_test_predict` to `y_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5157c0fe",
   "metadata": {},
   "source": [
    "5. Can you see what is the limitation of using simply accuracy ? What would be the problem if we had an unbalanced dataset ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f5962f",
   "metadata": {},
   "source": [
    "Precision reflects the repartition of the data, in the case of an unbalanced dataset, if we predicted always the same value we would get a good score even though our classifier is a constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69246108",
   "metadata": {},
   "source": [
    "### K-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c6546",
   "metadata": {},
   "source": [
    "The other, more robust approach we saw in class is k fold validation, which consists in using *k-1* fold for training and 1 fold for testing. We then compute an average/median of the performance metrics over all experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ca406",
   "metadata": {},
   "source": [
    "1. Create a function `k_fold_train_test` that will first shuffle an input matrix and then divide into k-fold with the number of folds specified as input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd380a",
   "metadata": {},
   "source": [
    "2. Use the k-fold algorithm to compute the average accuracy and recall the k folds. The algorithm will:\n",
    "    - Iterate over the k folds\n",
    "    - Train the model on the k-1 models\n",
    "    - Evaluate the performance on the 1 remaining fold and store it\n",
    "    - Compute the average/median performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7db85a",
   "metadata": {},
   "source": [
    "3. What problem do you see with this approach ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543775f4",
   "metadata": {},
   "source": [
    "## Using sklearn\n",
    "Sklearn is THE usual library for machine learning (but not so much deep learning), which comes with built-in methods (and many more) for training and performance evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e5fc26",
   "metadata": {},
   "source": [
    "1. Import different performance evaluation metrics by reading the documentation [here](https://scikit-learn.org/stable/modules/model_evaluation.html). (it's too long a read for a lab, but it's definitely an interesting read). Compare the `balanced_accuracy` and `accuracy` to our previous implementation (see [here](https://scikit-learn.org/stable/modules/model_evaluation.html#balanced-accuracy-score) for more). Compute the scores on `y` for the random classifier we implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f9d97a",
   "metadata": {},
   "source": [
    "2. Plenty of functions are available to split the dataset into train and test (see [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) for the complete list). Split `X` and `y` into train and test using the function `sklearn.model_selection.train_test_split`. What is the role of the `stratify` variable ? What problem does it solve ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6707536",
   "metadata": {},
   "source": [
    "3. Use the function `sklearn.model_selection.KFold` to get the proper indexes and perform cross validation on the random classifier using `balanced_accuracy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafb1b5b",
   "metadata": {},
   "source": [
    "# Conclusion and further works\n",
    "What do you think could be the use of this random classifier for the rest of our work on the titanic dataset ?\n",
    "\n",
    "\n",
    "**Highly advised bonus** (you will be able to use it during the exam): \n",
    "Create a Python module `utils.py` with the different functions and tools we coded today. We will re-use it throughout the rest of the labs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
