{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949f0928",
   "metadata": {},
   "source": [
    "# Lab3: Introduction to supervised learning\n",
    "This lab will be separated into two parts:\n",
    "\n",
    "1. First, we will code ourselves a random-based classifier and evaluate it using k-fold validation on the Titanic dataset.\n",
    "\n",
    "2. We will learn to do the same thing using the [sklearn](https://scikit-learn.org/stable/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2656a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef23e7c8",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "Load the Titanic dataset (or the `pre_processed.csv` one we did in the previous session)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d8ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94b0b44",
   "metadata": {},
   "source": [
    "Extract features into `X` and target `y` (conventional notations of `sklearn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d3dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am only extracting a few subset of variables, \n",
    "# because we are working on the random classifier, but you can take all the features we studied last lab\n",
    "X = df[[\"Age\", \"Fare\", \"Sex\"]].values\n",
    "y = df[\"Survived\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c664950",
   "metadata": {},
   "source": [
    "## Coding our own solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586918b5",
   "metadata": {},
   "source": [
    "### Coding a random classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715a1c80",
   "metadata": {},
   "source": [
    "1. Implement the simplest possible classifier: given a numpy vector and its ground truth, return a random value between 0 and 1 (use `numpy.random.binomial`). Make $p$ (the probability of being classified as 1) a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42fb8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_classifier(X, y, p: float = .5):\n",
    "    \"\"\"Random classifier: given a numpy vector X and a truth value y, return either the value 0 or 1, with probability p.\n",
    "    \n",
    "    Example:\n",
    "        random_classifier(np.array([1, 2, 3])) returns 1\n",
    "    \"\"\"\n",
    "    return np.random.binomial(1, p, X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca01dee",
   "metadata": {},
   "source": [
    "2. Apply this classifier on all values in the `X` numpy matrix and store it in `y_predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c521a630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Random predictions for Survival =======\n",
      "==== [1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0\n",
      " 1 1 1 1 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1\n",
      " 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1\n",
      " 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 1 1\n",
      " 1 0 0 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 0\n",
      " 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 0\n",
      " 0 1 1 0 0 1 1 0 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1\n",
      " 1 1 0 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1\n",
      " 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1\n",
      " 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0\n",
      " 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 1 0\n",
      " 0 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 0 0 1\n",
      " 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 0 0\n",
      " 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 1 1 1\n",
      " 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1\n",
      " 0 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1\n",
      " 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 0\n",
      " 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1\n",
      " 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1\n",
      " 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1\n",
      " 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"======== Random predictions for Survival =======\")\n",
    "y_predict = random_classifier(X, y)\n",
    "print(f\"==== {y_predict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc8366",
   "metadata": {},
   "source": [
    "3. Create the four evaluation functions we saw during lecture 4, that takes as iput :\n",
    "- `accuracy`\n",
    "- `recall`\n",
    "- `f1_score`\n",
    "- `precision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3353c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_predict):\n",
    "    \"\"\"Compute the accuracy between y and y_predict.\n",
    "    \n",
    "    Example:\n",
    "        accuracy([1, 1], [1, 1]) = 1\n",
    "    \"\"\"\n",
    "    return sum(y == y_predict)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "843cc346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y, y_predict):\n",
    "    \"\"\"Compute the prediction between y and y_predict.\n",
    "    \"\"\"\n",
    "    return sum((y == 1) & (y_predict == 1))/sum(y_predict == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d6f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y, y_predict):\n",
    "    \"\"\"Compute the recall between y and y_predict.\n",
    "    \"\"\"\n",
    "    return sum((y == 1) & (y_predict == 1))/sum(y == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31ad0e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y, y_predict):\n",
    "    \"\"\"Compute the F1 score between y and y_predict.\n",
    "    \"\"\"\n",
    "    computed_precision = precision(y, y_predict)\n",
    "    computed_recall = recall(y, y_predict)\n",
    "    return 2 * (computed_precision*computed_recall)/(computed_precision + computed_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f10c6a",
   "metadata": {},
   "source": [
    "4. Apply these functions to `y` and `y_predict` and draw conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "823caa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Accuracy\n",
      "0.5140291806958474\n",
      "========= Precision\n",
      "0.40130151843817785\n",
      "========= Recall\n",
      "0.5409356725146199\n",
      "========= F1 score\n",
      "0.46077210460772106\n"
     ]
    }
   ],
   "source": [
    "print(\"========= Accuracy\")\n",
    "print(f\"{accuracy(y, y_predict)}\")\n",
    "print(\"========= Precision\")\n",
    "print(f\"{precision(y, y_predict)}\")\n",
    "print(\"========= Recall\")\n",
    "print(f\"{recall(y, y_predict)}\")\n",
    "print(\"========= F1 score\")\n",
    "print(f\"{f1_score(y, y_predict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b85f9e",
   "metadata": {},
   "source": [
    "We can see that all scores are above .5, value that should be used to compare the quality of our algorithms to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e8d4e",
   "metadata": {},
   "source": [
    "### Separation between tests and train\n",
    "We will evaluate our algorithm by \"training\" it on a subset of the data `X_train`, `y_train` and evaluate it on the data `X_test`, and compare `y_test` with the ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61544d31",
   "metadata": {},
   "source": [
    "1. Is there a training phase of the random classifier ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc8959d",
   "metadata": {},
   "source": [
    "No !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb314bd7",
   "metadata": {},
   "source": [
    "2. Create a function `split_train_test` that takes as input a matrix `X` and a target `y` and randomly splits into two matrixes `X_train` and `X_test` and a target `y_train` and `y_test`. You can use the function `numpy.random.choice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5bc2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice, shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dee272a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(X, y, p_train = .5):\n",
    "    \"\"\"Random splits the numpy matrixes X into two sub-matrixes X_train, X_test, they target y into two sub targets y_train, y_test, with the ratio p (p sets to .5 means that half of X will be in test and the other half in train).\n",
    "    \n",
    "    Example:\n",
    "        split_train_test(X = np.array([1, 2], [3, 4], [3, 3]), y = [0, 0, 1], p=2/3) => (np.array( [3, 4], [3, 3]), np.array([0, 1])), (np.array([1, 2]), np.array([0]))\n",
    "    \"\"\"\n",
    "    # Select train index\n",
    "    train_indexes = choice(np.arange(X.shape[0]), replace=False, size=round(p_train*X.shape[0]))\n",
    "    # Get test indexes as a difference\n",
    "    test_indexes = np.array(list(set(np.arange(X.shape[0])) - set(train_indexes)))\n",
    "    # Index X and y accordingly\n",
    "    return X[train_indexes], X[test_indexes], y[train_indexes], y[test_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "172a0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_train_test(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41404f7d",
   "metadata": {},
   "source": [
    "3. Predict the value on the test dataset `X_test` on `y_test_predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2722ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = random_classifier(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4421e887",
   "metadata": {},
   "source": [
    "4. Compute the accuracy, precision, recall, f1_score by comparing `y_test_predict` to `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beb8c05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Accuracy\n",
      "0.46292134831460674\n",
      "========= Precision\n",
      "0.3760330578512397\n",
      "========= Recall\n",
      "0.5083798882681564\n",
      "========= F1 score\n",
      "0.43230403800475053\n"
     ]
    }
   ],
   "source": [
    "print(\"========= Accuracy\")\n",
    "print(f\"{accuracy(y_test, y_test_predict)}\")\n",
    "print(\"========= Precision\")\n",
    "print(f\"{precision(y_test, y_test_predict)}\")\n",
    "print(\"========= Recall\")\n",
    "print(f\"{recall(y_test, y_test_predict)}\")\n",
    "print(\"========= F1 score\")\n",
    "print(f\"{f1_score(y_test, y_test_predict)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5157c0fe",
   "metadata": {},
   "source": [
    "5. Can you see what is the limitation of using simply accuracy ? What would be the problem if we had an unbalanced dataset ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f5962f",
   "metadata": {},
   "source": [
    "Precision reflects the repartition of the data, in the case of an unbalanced dataset, if we predicted always the same value we would get a good score even though our classifier is a constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69246108",
   "metadata": {},
   "source": [
    "### K-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c6546",
   "metadata": {},
   "source": [
    "The other, more robust approach we saw in class is k fold validation, which consists in using *k-1* fold for training and 1 fold for testing. We then compute an average/median of the performance metrics over all experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ca406",
   "metadata": {},
   "source": [
    "1. Create a function `k_fold_train_test` that will first shuffle an input matrix and then divide into k-fold with the number of folds specified as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bf4c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_train_test(X, y, nbr_folds=3):\n",
    "    \"\"\"Shuffle the matrix X and the target vector y, and then returns as a tuple the k folds ((X_1, y_1), (X_2, y_2), ..., (X_k, y_k)).\n",
    "    \n",
    "    Example:\n",
    "        k_fold_train_test(np.array([1, 2], [3, 4], [3, 3], [3, 5]), y=np.array([1, 0, 0, 1]), nbr_folds=2) returns (np.array([1, 2], [3, 4]), np.array([1, 1])), np.array([3, 3], [3, 5]), np.array([0, 0]))\n",
    "    \"\"\"\n",
    "    # Will store folds\n",
    "    folds = []\n",
    "    # Get indexes and shuffle them\n",
    "    indexes = np.arange(len(X))\n",
    "    shuffle(indexes)\n",
    "    # Compute fold size (round)\n",
    "    fold_size = round(len(X)/nbr_folds)\n",
    "    # Iterate over indexes\n",
    "    index = 0\n",
    "    for fold in range(1, nbr_folds+1):\n",
    "        k_fold_index = indexes[index:index+fold_size]\n",
    "        folds.append((X[k_fold_index], y[k_fold_index]))\n",
    "        index += fold_size\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "904f78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = k_fold_train_test(X, y, nbr_folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd380a",
   "metadata": {},
   "source": [
    "2. Use the k-fold algorithm to compute the average accuracy and recall the k folds. The algorithm will:\n",
    "    - Iterate over the k folds\n",
    "    - Train the model on the k-1 models\n",
    "    - Evaluate the performance on the 1 remaining fold and store it\n",
    "    - Compute the average/median performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d415b32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Training classifier on 712 individuals \n",
      "======= Training classifier on 712 individuals \n",
      "======= Training classifier on 712 individuals \n",
      "======= Training classifier on 712 individuals \n",
      "======= Training classifier on 712 individuals \n"
     ]
    }
   ],
   "source": [
    "NBR_FOLDS = 5\n",
    "folds = k_fold_train_test(X, y, nbr_folds=NBR_FOLDS)\n",
    "\n",
    "accuracy_scores = []\n",
    "for fold in range(NBR_FOLDS):\n",
    "    # Concatenate all folds except the one with index fold\n",
    "    train_folds = [folds[fold_ix] for fold_ix in range(NBR_FOLDS) if fold_ix != fold]\n",
    "    X_train = np.concatenate([train_fold[0] for train_fold in train_folds])\n",
    "    y_train = np.concatenate([train_fold[1] for train_fold in train_folds])\n",
    "    # Retrieve test\n",
    "    X_test = folds[fold][0]\n",
    "    y_test = folds[fold][1]\n",
    "    # \"train\"\n",
    "    print(f\"======= Training classifier on {X_train.shape[0]} individuals \")\n",
    "    # Predict and compute score on test fold\n",
    "    y_fold_predict = random_classifier(X_test, y_test)\n",
    "    accuracy_scores.append(accuracy(y_test, y_fold_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e5761ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Median scores 0.5280898876404494\n",
      "======== Median scores 0.5044943820224719\n"
     ]
    }
   ],
   "source": [
    "print(f\"======== Median scores {np.median(accuracy_scores)}\")\n",
    "print(f\"======== Median scores {np.mean(accuracy_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7db85a",
   "metadata": {},
   "source": [
    "3. What problem do you see with this approach ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f5e9c",
   "metadata": {},
   "source": [
    "This approach is **non-reproducible**, which can cause some issues when writing a paper because our results cannot be reproduced. We should set the random seed to a value to avoid this approach (but then, this can introduce some bias as well)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543775f4",
   "metadata": {},
   "source": [
    "## Using sklearn\n",
    "Sklearn is THE usual library for machine learning (but not so much deep learning), which comes with built-in methods (and many more) for training and performance evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e5fc26",
   "metadata": {},
   "source": [
    "1. Import different performance evaluation metrics by reading the documentation [here](https://scikit-learn.org/stable/modules/model_evaluation.html). (it's a too long a read for a lab, but it's definitely an interesting read). Compare the `balanced_accuracy` and `accuracy` to our previous implementation (see [here](https://scikit-learn.org/stable/modules/model_evaluation.html#balanced-accuracy-score) for more). Compute the scores on `y` for the random classifier we implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ce5029",
   "metadata": {},
   "source": [
    "Imbalanced accuracy avoids performance bias in the case of unbalanced dataset. In the case of balanced dataset, it is equal to accuracy (in our case with Titanic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dc895d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdfac718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Balanced accuracy 0.5191017160387308\n",
      "======== Accuracy: 0.5140291806958474\n"
     ]
    }
   ],
   "source": [
    "print(f\"======== Balanced accuracy {balanced_accuracy_score(y, y_predict)}\")\n",
    "\n",
    "print(f\"======== Accuracy: {accuracy_score(y, y_predict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f9d97a",
   "metadata": {},
   "source": [
    "2. Plenty of functions are available to split the dataset into train and test (see [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) for the complete list). Split `X` and `y` into train and test using the function `sklearn.model_selection.train_test_split`. What is the role of the `stratify` variable ? What problem does it solve ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad62f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6707536",
   "metadata": {},
   "source": [
    "3. Use the function `sklearn.model_selection.KFold` to get the proper indexes and perform cross validation on the random classifier using `balanced_accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ddf346b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "indexes = KFold(n_splits=NBR_FOLDS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "978e363d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 0\n",
      "===== 'Train' model\n",
      "====== Predict on test fold\n",
      "Balanced accuracy 0.4936750130412102\n",
      "For fold 1\n",
      "===== 'Train' model\n",
      "====== Predict on test fold\n",
      "Balanced accuracy 0.5539364941278817\n",
      "For fold 2\n",
      "===== 'Train' model\n",
      "====== Predict on test fold\n",
      "Balanced accuracy 0.5147423352902805\n",
      "For fold 3\n",
      "===== 'Train' model\n",
      "====== Predict on test fold\n",
      "Balanced accuracy 0.4310160427807487\n",
      "For fold 4\n",
      "===== 'Train' model\n",
      "====== Predict on test fold\n",
      "Balanced accuracy 0.48049575994781474\n",
      "===========\n",
      "===========\n",
      "Median accuracy: 0.4936750130412102\n"
     ]
    }
   ],
   "source": [
    "balanced_accuracy_scores = []\n",
    "for ix, (train_index, test_index) in enumerate(indexes.split(X)):\n",
    "    print(f\"For fold {ix}\")\n",
    "    print(\"===== 'Train' model\")\n",
    "    print(f\"====== Predict on test fold\")\n",
    "    y_predict_fold = random_classifier(X[test_index], y[test_index])\n",
    "    balanced_accuracy = balanced_accuracy_score(y[test_index], y_predict_fold)\n",
    "    print(f\"Balanced accuracy {balanced_accuracy}\")\n",
    "    balanced_accuracy_scores.append(balanced_accuracy)\n",
    "    \n",
    "print(\"===========\")\n",
    "print(\"===========\")\n",
    "print(f\"Median accuracy: {np.median(balanced_accuracy_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafb1b5b",
   "metadata": {},
   "source": [
    "# Conclusion and further works\n",
    "What do you think could be the use of this random classifier for the rest of our work on the titanic dataset ?\n",
    "\n",
    "**We will use it as a comparison to other classifiers !**.\n",
    "\n",
    "\n",
    "**Highly advised bonus** (you will be able to use it during the exam): \n",
    "Create a Python module `utils.py` with the different functions and tools we coded today. We will re-use it throughout the rest of the labs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
