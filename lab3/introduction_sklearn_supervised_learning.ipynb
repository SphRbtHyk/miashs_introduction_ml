{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949f0928",
   "metadata": {},
   "source": [
    "# Lab3: Introduction to supervised learning\n",
    "This lab will be separated into two parts:\n",
    "\n",
    "1. First, we will code ourselves a random-based classifier and evaluate it using k-fold validation on the Titanic dataset.\n",
    "\n",
    "2. We will learn to do the same thing using the [sklearn](https://scikit-learn.org/stable/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2656a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef23e7c8",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "Load the Titanic dataset (or the `pre_processed.csv` one we did in the previous session)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d8ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94b0b44",
   "metadata": {},
   "source": [
    "Extract features into `X` and target `y` (conventional notations of `sklearn`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c664950",
   "metadata": {},
   "source": [
    "## Coding our own solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586918b5",
   "metadata": {},
   "source": [
    "### Coding a random classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715a1c80",
   "metadata": {},
   "source": [
    "1. Implement the simplest possible classifier: given a numpy vector, return a random value between 0 and 1 (use `numpy.random.binomial`). Make $p$ (the probability of being classified as 1) a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42fb8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_classifier(X, p: float = .5):\n",
    "    \"\"\"Random classifier: given a numpy vector X, return either the value 0 or 1, with probability p.\n",
    "    \n",
    "    Example:\n",
    "        random_classifier(np.array([1, 2, 3])) returns 1\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca01dee",
   "metadata": {},
   "source": [
    "2. Apply this classifier on all values in the `X` numpy matrix and store it in `y_predict`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc8366",
   "metadata": {},
   "source": [
    "3. Create the four evaluation functions we saw during lecture 4, that takes as iput :\n",
    "- `accuracy`\n",
    "- `recall`\n",
    "- `f1_score`\n",
    "- `precision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f3353c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_predict):\n",
    "    \"\"\"Compute the accuracy between y and y_predict.\n",
    "    \n",
    "    Example:\n",
    "        accuracy([1, 1], [1, 1]) = 1\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f10c6a",
   "metadata": {},
   "source": [
    "4. Apply these functions to `y` and `y_predict` and draw conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e8d4e",
   "metadata": {},
   "source": [
    "### Separation between tests and train\n",
    "We will evaluate our algorithm by \"training\" it on a subset of the data `X_train`, `y_train` and evaluate it on the data `X_test`, and compare `y_test` with the ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61544d31",
   "metadata": {},
   "source": [
    "1. Is there a training phase of the random classifier ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb314bd7",
   "metadata": {},
   "source": [
    "2. Create a function `split_train_test` that takes as input a matrix `X` and a target `y` and randomly splits into two matrixes `X_train` and `X_test` and a target `y_train` and `y_test`. You can use the function `numpy.random.sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dee272a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(X, y, p_train = .5):\n",
    "    \"\"\"Random splits the numpy matrixes X into two sub-matrixes X_train, X_test, they target y into two sub targets y_train, y_test, with the ratio p (p sets to .5 means that half of X will be in test and the other half in train).\n",
    "    \n",
    "    Example:\n",
    "        split_train_test(X = np.array([1, 2], [3, 4], [3, 3]), y = [0, 0, 1], p=2/3) => (np.array( [3, 4], [3, 3]), np.array([0, 1])), (np.array([1, 2]), np.array([0]))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41404f7d",
   "metadata": {},
   "source": [
    "3. Predict the value on the test dataset `X_test` on `y_test_predict`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4421e887",
   "metadata": {},
   "source": [
    "4. Compute the accuracy, precision, recall, f1_score by comparing `y_test_predict` to `y_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5157c0fe",
   "metadata": {},
   "source": [
    "5. Can you see what is the limitation of using simply ? What would be the problem if we had an unbalanced dataset ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69246108",
   "metadata": {},
   "source": [
    "### K-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c6546",
   "metadata": {},
   "source": [
    "The other, more robust approach we saw in class is k fold validation, which consists in using *k-1* fold for training and 1 fold for testing. We then compute an average/median of the performance metrics over all experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ca406",
   "metadata": {},
   "source": [
    "1. Create a function `k_fold_train_test` that will first shuffle an input matrix and then divide into k-fold with the number of folds specified as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bf4c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_train_test(X, y, nbr_folds=3):\n",
    "    \"\"\"Shuffle the matrix X and the target vector y, and then returns as a tuple the k folds ((X_1, y_1), (X_2, y_2), ..., (X_k, y_k)).\n",
    "    \n",
    "    Example:\n",
    "        k_fold_train_test(np.array([1, 2], [3, 4], [3, 3], [3, 5]), y=np.array([1, 0, 0, 1]), nbr_folds=2) returns (np.array([1, 2], [3, 4]), np.array([1, 1])), np.array([3, 3], [3, 5]), np.array([0, 0]))\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd380a",
   "metadata": {},
   "source": [
    "2. Use the k-fold algorithm to compute the average accuracy and recall the k folds. The algorithm will:\n",
    "    - Iterate over the k folds\n",
    "    - Train the model on the k-1 models\n",
    "    - Evaluate the performance on the 1 remaining fold and store it\n",
    "    - Compute the average/median performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7db85a",
   "metadata": {},
   "source": [
    "3. What problem do you see with this approach ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543775f4",
   "metadata": {},
   "source": [
    "## Using sklearn\n",
    "Sklearn is THE usual library for machine learning (but not so much deep learning), which comes with built-in methods (and many more) for training and performance evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e5fc26",
   "metadata": {},
   "source": [
    "1. Import different performance evaluation metrics by reading the documentation [here](https://scikit-learn.org/stable/modules/model_evaluation.html). (it's a too long a read for a lab, but it's definitely an interesting read). Compare the `balanced_accuracy` and `accuracy` to our previous implementation (see [here](https://scikit-learn.org/stable/modules/model_evaluation.html#balanced-accuracy-score) for more). Compute the scores on `y` for the random classifier we implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f9d97a",
   "metadata": {},
   "source": [
    "2. Plenty of functions are available to split the dataset into train and test (see [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) for the complete list). Split `X` and `y` into train and test using the function `sklearn.model_selection.train_test_split`. What is the role of the `stratify` variable ? What problem does it solve ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6707536",
   "metadata": {},
   "source": [
    "3. Use the function `sklearn.model_selection.KFold` to get the proper indexes and perform cross validation on the random classifier using `balanced_accuracy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafb1b5b",
   "metadata": {},
   "source": [
    "# Conclusion and further works\n",
    "What do you think could be the use of this random classifier for the rest of our work on the titanic dataset ?\n",
    "\n",
    "**Highly advised bonus** (you will be able to use it during the exam): \n",
    "Create a Python module `utils.py` with the different functions and tools we coded today. We will re-use it throughout the rest of the labs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
